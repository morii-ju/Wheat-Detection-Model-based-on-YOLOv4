{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKFAqfYubiHF"
      },
      "outputs": [],
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/bin | grep nvidia\n",
        "!echo $PATH"
      ],
      "metadata": {
        "id": "Qz7OfskdbpQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "JaPxDdmRbrR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the dataset"
      ],
      "metadata": {
        "id": "LUYtgtNwbrqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade dataset-tools"
      ],
      "metadata": {
        "id": "2Ttk8aAGbtUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dataset_tools as dtools\n",
        "dtools.download(dataset='deepNIR Fruit Detection', dst_dir='/content/dataset-ninja/')"
      ],
      "metadata": {
        "id": "htF1Pifwbv9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the structure of this dataset"
      ],
      "metadata": {
        "id": "fFnPS30VbybZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/dataset-ninja/deepnir-fruit-detection"
      ],
      "metadata": {
        "id": "SygwA1zlbw4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths\n",
        "train_path = \"/content/dataset-ninja/deepnir-fruit-detection/train\"\n",
        "val_path = \"/content/dataset-ninja/deepnir-fruit-detection/valid\"\n",
        "test_path = \"/content/dataset-ninja/deepnir-fruit-detection/test\"\n",
        "\n",
        "# List the contents of the img and ann directories\n",
        "train_img_files = os.listdir(os.path.join(train_path, \"img\"))\n",
        "train_ann_files = os.listdir(os.path.join(train_path, \"ann\"))\n",
        "val_img_files = os.listdir(os.path.join(val_path, \"img\"))\n",
        "val_ann_files = os.listdir(os.path.join(val_path, \"ann\"))\n",
        "test_img_files = os.listdir(os.path.join(test_path, \"img\"))\n",
        "test_ann_files = os.listdir(os.path.join(test_path, \"ann\"))\n",
        "\n",
        "print(\"Number of train images:\", len(train_img_files))\n",
        "print(\"Number of train annotations:\", len(train_ann_files))\n",
        "print(\"Number of val images:\", len(val_img_files))\n",
        "print(\"Number of val annotations:\", len(val_ann_files))\n",
        "print(\"Number of test images:\", len(test_img_files))\n",
        "print(\"Number of test annotations:\", len(test_ann_files))\n",
        "\n",
        "# Create directories if not exist\n",
        "os.makedirs(os.path.join(train_path, \"img\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_path, \"ann\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_path, \"img\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_path, \"ann\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_path, \"img\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_path, \"ann\"), exist_ok=True)"
      ],
      "metadata": {
        "id": "Om4tKKVIcQWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discover the \"img\" and \"ann\"\n",
        "# Print the first five files in each directory\n",
        "print(\"First five files in 'img':\", train_img_files[:5])\n",
        "print(\"First five files in 'ann':\", train_ann_files[:5])"
      ],
      "metadata": {
        "id": "3q9KEgKhdanE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##if training with only wheat positives, run the following section"
      ],
      "metadata": {
        "id": "cwXAlUcgQO_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that it's not sorted, so we need to pair them up manually: ann name(.jpg) = file name.jpg(.json)\n",
        "\n",
        "Also filter to have only bounding boxes for the wheat class"
      ],
      "metadata": {
        "id": "SzGJEQN-ddBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "def filter_bounding_boxes(img_dir, ann_dir, visualize=False):\n",
        "    \"\"\"\n",
        "    Filters images and annotations to include only those with bounding boxes\n",
        "    for the specified class.\n",
        "\n",
        "    Args:\n",
        "        img_dir (str): Directory containing image files.\n",
        "        ann_dir (str): Directory containing annotation files.\n",
        "        visualize (bool): If True, displays bounding boxes on the image.\n",
        "\n",
        "    Returns:\n",
        "        list: Filtered image file paths.\n",
        "        list: Filtered annotation file paths.\n",
        "    \"\"\"\n",
        "    filtered_imgs = []\n",
        "    filtered_anns = []\n",
        "\n",
        "    for img_file in sorted(os.listdir(img_dir)):\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "        ann_file = img_file + \".json\"  # Match image file\n",
        "        ann_path = os.path.join(ann_dir, ann_file)\n",
        "\n",
        "        with open(ann_path, 'r') as f:\n",
        "            annotation = json.load(f)\n",
        "\n",
        "        # Check if the annotation contains at least one bounding box for the class\n",
        "        contains_class = any(\n",
        "            obj[\"classTitle\"] == \"wheat\" and obj[\"geometryType\"] == \"rectangle\"\n",
        "            for obj in annotation.get(\"objects\", [])\n",
        "        )\n",
        "\n",
        "        if contains_class:\n",
        "            filtered_imgs.append(img_path)\n",
        "            filtered_anns.append(ann_path)\n",
        "\n",
        "            # Visualization (if enabled)\n",
        "            if visualize:\n",
        "                print(f\"Visualizing: {img_path}\")\n",
        "                bounding_boxes = [\n",
        "                    obj[\"points\"][\"exterior\"]\n",
        "                    for obj in annotation[\"objects\"]\n",
        "                    if obj[\"classTitle\"] == \"wheat\" and obj[\"geometryType\"] == \"rectangle\"\n",
        "                ]\n",
        "\n",
        "                # Open and display the image with bounding boxes\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "                fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "                ax.imshow(img)\n",
        "\n",
        "                # Add bounding boxes\n",
        "                for bbox in bounding_boxes:\n",
        "                    x_min, y_min = bbox[0]\n",
        "                    x_max, y_max = bbox[1]\n",
        "                    width = x_max - x_min\n",
        "                    height = y_max - y_min\n",
        "                    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='red', facecolor='none')\n",
        "                    ax.add_patch(rect)\n",
        "\n",
        "                ax.set_title(f\"Bounding Boxes for {img_path}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "            # Extract detected object\n",
        "            detected_objects = [obj[\"classTitle\"] for obj in annotation.get(\"objects\", [])]\n",
        "            # print(f\"Object Class is: {detected_objects[0]}\")\n",
        "\n",
        "            # Count the number of detected objects\n",
        "            num_objects = len(detected_objects)\n",
        "            print(f\"{img_file}: Object Class is {detected_objects[0]}; Num detected: {num_objects}\")\n",
        "\n",
        "    print(f\"Filtered {len(filtered_imgs)} images and annotations.\")\n",
        "\n",
        "    return filtered_imgs, filtered_anns"
      ],
      "metadata": {
        "id": "cGb0Gyazdh2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "set visualize=True if want visualization of images"
      ],
      "metadata": {
        "id": "uktB1fMuQpoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs, train_anns = filter_bounding_boxes(os.path.join(train_path, \"img\"), os.path.join(train_path, \"ann\"))\n",
        "val_imgs, val_anns = filter_bounding_boxes(os.path.join(val_path, \"img\"), os.path.join(val_path, \"ann\"))\n",
        "test_imgs, test_anns = filter_bounding_boxes(os.path.join(test_path, \"img\"), os.path.join(test_path, \"ann\"))"
      ],
      "metadata": {
        "id": "e_Sf1UJEdgXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_filtered_data(img_paths, ann_paths, img_dest, ann_dest):\n",
        "    \"\"\"\n",
        "    Saves filtered images and annotations into specified directories.\n",
        "\n",
        "    Args:\n",
        "        img_paths (list): List of image file paths.\n",
        "        ann_paths (list): List of annotation file paths.\n",
        "        img_dest (str): Destination directory for images.\n",
        "        ann_dest (str): Destination directory for annotations.\n",
        "    \"\"\"\n",
        "    os.makedirs(img_dest, exist_ok=True)\n",
        "    os.makedirs(ann_dest, exist_ok=True)\n",
        "\n",
        "    for img_path, ann_path in zip(img_paths, ann_paths):\n",
        "        shutil.copy(img_path, img_dest)\n",
        "        shutil.copy(ann_path, ann_dest)\n",
        "\n",
        "# Paths for saving filtered data\n",
        "filtered_train_path = \"/content/dataset-ninja/wheat/train\"\n",
        "filtered_val_path = \"/content/dataset-ninja/wheat/val\"\n",
        "filtered_test_path = \"/content/dataset-ninja/wheat/test\"\n",
        "\n",
        "# Save filtered datasets\n",
        "save_filtered_data(train_imgs, train_anns, os.path.join(filtered_train_path, \"img\"), os.path.join(filtered_train_path, \"ann\"))\n",
        "save_filtered_data(val_imgs, val_anns, os.path.join(filtered_val_path, \"img\"), os.path.join(filtered_val_path, \"ann\"))\n",
        "save_filtered_data(test_imgs, test_anns, os.path.join(filtered_test_path, \"img\"), os.path.join(filtered_test_path, \"ann\"))\n",
        "\n",
        "# Final counts\n",
        "print(f\"Filtered Training set: {len(train_imgs)} images, {len(train_anns)} annotations\")\n",
        "print(f\"Filtered Validation set: {len(val_imgs)} images, {len(val_anns)} annotations\")\n",
        "print(f\"Filtered Test set: {len(test_imgs)} images, {len(test_anns)} annotations\")"
      ],
      "metadata": {
        "id": "IlSrOXi-jes5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##YOLO"
      ],
      "metadata": {
        "id": "vsAEfGFAj7VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def convert_to_yolo_format(ann_path, img_shape, output_path):\n",
        "    \"\"\"\n",
        "    Convert annotation JSON to YOLO format and save to a .txt file.\n",
        "\n",
        "    Args:\n",
        "        ann_path (str): Path to the annotation JSON.\n",
        "        img_shape (tuple): Shape of the image (width, height).\n",
        "        output_path (str): Path to save the YOLO formatted annotation.\n",
        "    \"\"\"\n",
        "    with open(ann_path, 'r') as f:\n",
        "        annotation = json.load(f)\n",
        "\n",
        "    height, width = img_shape\n",
        "    with open(output_path, 'w') as f:\n",
        "        for obj in annotation.get(\"objects\", []):\n",
        "            if obj[\"classTitle\"] == \"wheat\"  and obj[\"geometryType\"] == \"rectangle\":\n",
        "                # Normalize bounding box coordinates\n",
        "                x_min, y_min = obj[\"points\"][\"exterior\"][0]\n",
        "                x_max, y_max = obj[\"points\"][\"exterior\"][1]\n",
        "                x_center = (x_min + x_max) / 2 / width\n",
        "                y_center = (y_min + y_max) / 2 / height\n",
        "                box_width = (x_max - x_min) / width\n",
        "                box_height = (y_max - y_min) / height\n",
        "\n",
        "                # Write to file in YOLO format: <class_id> <x_center> <y_center> <width> <height>\n",
        "                f.write(f\"0 {x_center} {y_center} {box_width} {box_height}\\n\")"
      ],
      "metadata": {
        "id": "6t8c73KTTTI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_dataset(img_dir, ann_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for img_file in os.listdir(img_dir):\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "        ann_file = img_file + \".json\"\n",
        "        ann_path = os.path.join(ann_dir, ann_file)\n",
        "        output_path = os.path.join(output_dir, img_file.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        # Get image dimensions\n",
        "        img = Image.open(img_path)\n",
        "        img_shape = img.size  # (width, height)\n",
        "\n",
        "        # Convert annotation\n",
        "        convert_to_yolo_format(ann_path, img_shape, output_path)\n",
        "\n",
        "convert_dataset(\n",
        "    img_dir=os.path.join(filtered_train_path, \"img\"),\n",
        "    ann_dir=os.path.join(filtered_train_path, \"ann\"),\n",
        "    output_dir=os.path.join(filtered_train_path, \"labels\")\n",
        ")\n",
        "convert_dataset(\n",
        "    img_dir=os.path.join(filtered_val_path, \"img\"),\n",
        "    ann_dir=os.path.join(filtered_val_path, \"ann\"),\n",
        "    output_dir=os.path.join(filtered_val_path, \"labels\")\n",
        ")\n",
        "convert_dataset(\n",
        "    img_dir=os.path.join(filtered_test_path, \"img\"),\n",
        "    ann_dir=os.path.join(filtered_test_path, \"ann\"),\n",
        "    output_dir=os.path.join(filtered_test_path, \"labels\")\n",
        ")"
      ],
      "metadata": {
        "id": "J7JhBEGZTXyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate .txt\n",
        "def generate_image_list(img_dir, output_path):\n",
        "    with open(output_path, 'w') as f:\n",
        "        for img_file in os.listdir(img_dir):\n",
        "            img_path = os.path.join(img_dir, img_file)\n",
        "            f.write(f\"{img_path}\\n\")\n",
        "\n",
        "generate_image_list(\n",
        "    img_dir=os.path.join(filtered_train_path, \"img\"),\n",
        "    output_path=os.path.join(filtered_train_path, \"train.txt\")\n",
        ")\n",
        "generate_image_list(\n",
        "    img_dir=os.path.join(filtered_val_path, \"img\"),\n",
        "    output_path=os.path.join(filtered_val_path, \"val.txt\")\n",
        ")\n",
        "generate_image_list(\n",
        "    img_dir=os.path.join(filtered_test_path, \"img\"),\n",
        "    output_path=os.path.join(filtered_test_path, \"test.txt\")\n",
        ")"
      ],
      "metadata": {
        "id": "fdQWY_X_Tbo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/dataset-ninja/wheat/train/labels/*.txt /content/dataset-ninja/wheat/train/img/\n",
        "!mv /content/dataset-ninja/wheat/val/labels/*.txt /content/dataset-ninja/wheat/val/img/"
      ],
      "metadata": {
        "id": "f9arl1tMThJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To test with a single file"
      ],
      "metadata": {
        "id": "iWW1Pb5NSDTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install darknet (YOLOv4 framework) and other dependencies\n",
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "%cd darknet\n",
        "\n",
        "# Build Darknet with GPU and OpenCV support\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "metadata": {
        "id": "ssJHSUJaSSxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "60NmrAPBScXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/dataset-ninja/wheat/single/\", exist_ok=True)"
      ],
      "metadata": {
        "id": "B_Jj3rPsSZ7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/dataset-ninja/wheat/train/img/dbfd38b38_jpg.rf.0b2e8a2670b8b16dbd6b7e4dd0e98ff6.jpg\" \"/content/dataset-ninja/wheat/single/\""
      ],
      "metadata": {
        "id": "uOT-lVcvTkGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/dataset-ninja/wheat/train/img/dbfd38b38_jpg.rf.0b2e8a2670b8b16dbd6b7e4dd0e98ff6.txt\" \"/content/dataset-ninja/wheat/single/\""
      ],
      "metadata": {
        "id": "N60axCW5TleQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"/content/dataset-ninja/wheat/single/dbfd38b38_jpg.rf.0b2e8a2670b8b16dbd6b7e4dd0e98ff6.jpg\" > /content/dataset-ninja/wheat/single/train.txt"
      ],
      "metadata": {
        "id": "gZI6iKVoTnOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights"
      ],
      "metadata": {
        "id": "V6On9noBTojU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"wheat\" > /content/darknet/data/obj.names"
      ],
      "metadata": {
        "id": "-Mz3dGyKSfa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/darknet/obj.data\", \"w\") as f:\n",
        "    f.write(\"\"\"classes=1\n",
        "train=/content/dataset-ninja/wheat/single/train.txt\n",
        "valid=/content/dataset-ninja/wheat/single/train.txt\n",
        "names=/content/darknet/data/obj.names\n",
        "backup=/content/darknet/backup/\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Z7c12ru6SEAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_path = \"/content/darknet/cfg/yolov4-custom.cfg\"\n",
        "\n",
        "with open(cfg_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "num_classes = 1\n",
        "filters = (num_classes + 5) * 3\n",
        "\n",
        "updated_lines = []\n",
        "for line in lines:\n",
        "    if line.strip().startswith(\"batch=\"):\n",
        "        updated_lines.append(\"batch=64\\n\")\n",
        "    elif line.strip().startswith(\"subdivisions=\"):\n",
        "        updated_lines.append(\"subdivisions=4\\n\")\n",
        "    elif line.strip().startswith(\"max_batches = \"):\n",
        "        updated_lines.append(\"max_batches=2000\\n\")\n",
        "        print(updated_lines)\n",
        "    elif line.strip().startswith(\"steps=\"):\n",
        "        max_batches = num_classes * 2000\n",
        "        updated_lines.append(f\"steps={int(0.8 * max_batches)},{int(0.9 * max_batches)}\\n\")\n",
        "    elif line.strip().startswith(\"filters=\"):\n",
        "        updated_lines.append(f\"filters={filters}\\n\")\n",
        "    elif line.strip().startswith(\"classes=\"):\n",
        "        updated_lines.append(f\"classes={num_classes}\\n\")\n",
        "    else:\n",
        "        updated_lines.append(line)\n",
        "\n",
        "with open(cfg_path, \"w\") as f:\n",
        "    f.writelines(updated_lines)\n",
        "\n",
        "print(f\"Configuration file updated at: {cfg_path}\")"
      ],
      "metadata": {
        "id": "V6Y7q9qrSllj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !./darknet detector map /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg /content/darknet/yolov4.conv.137 -map\n",
        "\n",
        "!./darknet detector train /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg /content/darknet/yolov4.weights -map"
      ],
      "metadata": {
        "id": "sHo5cpqTT6DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector test /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg /content/darknet/yolov4.weights -ext_output -dont_show < /content/dataset-ninja/wheat/single/train.txt"
      ],
      "metadata": {
        "id": "zYvkCGIbT9WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image as IPImage, display\n",
        "\n",
        "display(IPImage(filename='/content/darknet/predictions.jpg'))"
      ],
      "metadata": {
        "id": "DZmqjqCMT_Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To run on the entire dataset"
      ],
      "metadata": {
        "id": "6rw-JYRvSTzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install darknet (YOLOv4 framework) and other dependencies\n",
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "%cd darknet\n",
        "\n",
        "# Build Darknet with GPU and OpenCV support\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "metadata": {
        "id": "3f9XAfNV4Una"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
        "!make"
      ],
      "metadata": {
        "id": "BEiGUFlo7KGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display dimensions of the first 10 images\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "img_dir = '/content/dataset-ninja/wheat/train/img'\n",
        "dimensions = [Image.open(os.path.join(img_dir, f)).size for f in os.listdir(img_dir)]\n",
        "print(dimensions[:10])"
      ],
      "metadata": {
        "id": "tNhrZRfG5LNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"wheat\" > /content/darknet/data/obj.names"
      ],
      "metadata": {
        "id": "5EP13c2e3p46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/darknet/obj.data\", \"w\") as f:\n",
        "    f.write(\"\"\"classes=1\n",
        "train=/content/dataset-ninja/wheat/train/train.txt\n",
        "valid=/content/dataset-ninja/wheat/val/val.txt\n",
        "names=/content/darknet/data/obj.names\n",
        "backup=/content/darknet/backup/\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "X8GdoE-749W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_path = \"/content/darknet/cfg/yolov4-custom.cfg\"\n",
        "\n",
        "with open(cfg_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "num_classes = 1\n",
        "filters = (num_classes + 5) * 3\n",
        "\n",
        "updated_lines = []\n",
        "for line in lines:\n",
        "    if line.strip().startswith(\"batch=\"):\n",
        "        updated_lines.append(\"batch=64\\n\")\n",
        "    elif line.strip().startswith(\"subdivisions=\"):\n",
        "        updated_lines.append(\"subdivisions=4\\n\")\n",
        "    elif line.strip().startswith(\"max_batches = \"):\n",
        "        updated_lines.append(\"max_batches=2000\\n\")\n",
        "        print(updated_lines)\n",
        "    elif line.strip().startswith(\"steps=\"):\n",
        "        max_batches = num_classes * 2000\n",
        "        updated_lines.append(f\"steps={int(0.8 * max_batches)},{int(0.9 * max_batches)}\\n\")\n",
        "    elif line.strip().startswith(\"filters=\"):\n",
        "        updated_lines.append(f\"filters={filters}\\n\")\n",
        "    elif line.strip().startswith(\"classes=\"):\n",
        "        updated_lines.append(f\"classes={num_classes}\\n\")\n",
        "    else:\n",
        "        updated_lines.append(line)\n",
        "\n",
        "with open(cfg_path, \"w\") as f:\n",
        "    f.writelines(updated_lines)\n",
        "\n",
        "print(f\"Configuration file updated at: {cfg_path}\")"
      ],
      "metadata": {
        "id": "VhtTd0xK8s_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting yolov4.conv.137 weights\n",
        "# !wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.conv.137 -P /content/darknet/\n",
        "\n",
        "# getting yolov4.weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights -P /content/darknet/"
      ],
      "metadata": {
        "id": "l0nv9_H-FWZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv4\n",
        "!./darknet detector train /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg yolov4.conv.137 -map -dont_show -saveweights 100"
      ],
      "metadata": {
        "id": "JxLQeOwh3bdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for debug - Evaluate mAP\n",
        "\n",
        "# if completed training:\n",
        "# !./darknet detector map /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg /content/darknet/backup/yolov4-custom_best.weights\n",
        "\n",
        "# otherwise:\n",
        "# !./darknet detector map /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg /content/darknet/backup/yolov4-custom_last.weights"
      ],
      "metadata": {
        "id": "tGzWbV9A3wZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions on Test Images, The predictions will be stored in result.json"
      ],
      "metadata": {
        "id": "hdsZsbSj31GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test images\n",
        "!./darknet detector test /content/darknet/obj.data /content/darknet/cfg/yolov4-custom.cfg /content/darknet/backup/yolov4-custom_last.weights -ext_output -dont_show -thresh 0.1 -out result.json < /content/dataset-ninja/wheat/test/test.txt"
      ],
      "metadata": {
        "id": "aHxEdLHhTGHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat result.json"
      ],
      "metadata": {
        "id": "V2mFWLDFSbbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Future measurement steps"
      ],
      "metadata": {
        "id": "dxkBD70jSv98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def compute_iou(pred_box, gt_box):\n",
        "    x_min = max(pred_box[0], gt_box[0])\n",
        "    y_min = max(pred_box[1], gt_box[1])\n",
        "    x_max = min(pred_box[2], gt_box[2])\n",
        "    y_max = min(pred_box[3], gt_box[3])\n",
        "    inter_area = max(0, x_max - x_min) * max(0, y_max - y_min)\n",
        "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - gt_box[1])\n",
        "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
        "    return inter_area / (pred_area + gt_area - inter_area + 1e-6)\n",
        "\n",
        "def load_ground_truths(annotation_dir):\n",
        "    ground_truths = {}\n",
        "    for file_name in os.listdir(annotation_dir):\n",
        "        if file_name.endswith(\".json\"):\n",
        "            file_path = os.path.join(annotation_dir, file_name)\n",
        "            with open(file_path, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                # Extract bounding boxes in [x_min, y_min, x_max, y_max] format\n",
        "                boxes = [\n",
        "                    [obj[\"x_min\"], obj[\"y_min\"], obj[\"x_max\"], obj[\"y_max\"]]\n",
        "                    for obj in data.get(\"annotations\", [])\n",
        "                ]\n",
        "                ground_truths[file_name.replace(\".json\", \".jpg\")] = boxes\n",
        "    return ground_truths\n",
        "\n",
        "def calculate_metrics(predictions, ground_truths):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "\n",
        "    for img, preds in predictions.items():\n",
        "        gt_boxes = ground_truths.get(img, [])\n",
        "        matched = [False] * len(gt_boxes)  # Track matched ground truths\n",
        "\n",
        "        for pred in preds:\n",
        "            iou_scores = [compute_iou(pred, gt) for gt in gt_boxes]\n",
        "            max_iou = max(iou_scores) if iou_scores else 0\n",
        "            max_iou_idx = iou_scores.index(max_iou) if iou_scores else -1\n",
        "\n",
        "            if max_iou >= 0.5 and not matched[max_iou_idx]:\n",
        "                tp += 1\n",
        "                matched[max_iou_idx] = True  # Mark this ground truth as matched\n",
        "            else:\n",
        "                fp += 1\n",
        "\n",
        "        fn += sum(1 for m in matched if not m)  # Unmatched ground truths are false negatives\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Paths\n",
        "annotation_dir = \"/content/dataset-ninja/wheat/ann/\"\n",
        "results_path = \"/content/result.json\"\n",
        "\n",
        "# Load ground truths\n",
        "ground_truths = load_ground_truths(annotation_dir)\n",
        "\n",
        "# Load predictions\n",
        "with open(results_path, \"r\") as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Calculate metrics\n",
        "metrics = calculate_metrics(predictions, ground_truths)\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "UoaWSB9w6CXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}