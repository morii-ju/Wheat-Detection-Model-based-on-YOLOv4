# -*- coding: utf-8 -*-
"""dl_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V16J2FhmkuPaBFEMKje2wHasxKc2g_fF
"""

# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.
!/usr/local/cuda/bin/nvcc --version
# We need to install the correct cuDNN according to this output

!ls /usr/bin | grep nvidia
!echo $PATH

!nvidia-smi

"""Add the dataset"""

pip install --upgrade dataset-tools

import dataset_tools as dtools

dtools.download(dataset='deepNIR Fruit Detection', dst_dir='~/dataset-ninja/')

"""Check the structure of this dataset"""

!ls /root/dataset-ninja/deepnir-fruit-detection

# explore the categories under train
import os

dataset_path = "/root/dataset-ninja/deepnir-fruit-detection/train"

# List the contents of the training directory
categories = os.listdir(dataset_path)
print("Categories in train:", categories)

# Get the items under both cetegories
img_dir = os.path.join(dataset_path, "img")
ann_dir = os.path.join(dataset_path, "ann")

# List the contents of the img and ann directories
img_files = os.listdir(img_dir)
ann_files = os.listdir(ann_dir)

print("Number of images:", len(img_files))
print("Number of annotations:", len(ann_files))

# Get the number of items under testing class
test_path = "/root/dataset-ninja/deepnir-fruit-detection/test"
test_img_dir = os.path.join(test_path, "img")
test_ann_dir = os.path.join(test_path, "ann")

test_img_files = os.listdir(test_img_dir)
test_ann_files = os.listdir(test_ann_dir)

print("Number of testing images:", len(test_img_files))
print("Number of testing annotations:", len(test_ann_files))

# Get the number of items under validation class
valid_path = "/root/dataset-ninja/deepnir-fruit-detection/valid"
valid_img_dir = os.path.join(valid_path, "img")
valid_ann_dir = os.path.join(valid_path, "ann")

valid_img_files = os.listdir(valid_img_dir)
valid_ann_files = os.listdir(valid_ann_dir)

print("Number of validation images:", len(valid_img_files))
print("Number of validation annotations:", len(valid_ann_files))

"""Keep those with class_type = wheat"""

import json
# check the class_type of each image
for img_file, ann_file in zip(img_files, ann_files):
    img_path = os.path.join(img_dir, img_file)
    ann_path = os.path.join(ann_dir, ann_file)

    # Load the annotation
    with open(ann_path, 'r') as f:
        annotation = json.load(f)

    # Check the class type
    if annotation.get("objects") and annotation["objects"][0]["classTitle"] != "wheat":
        # Delete the image and annotation files
        os.remove(img_path)
        os.remove(ann_path)

# List image and annotation files
img_files = sorted(os.listdir(img_dir))
ann_files = sorted(os.listdir(ann_dir))

print("Number of images after cleaning:", len(img_files))
print("Number of annotations after cleaning:", len(ann_files))

for valid_img_file, valid_ann_file in zip(valid_img_files, valid_ann_files):
    valid_img_path = os.path.join(valid_img_dir, valid_img_file)
    valid_ann_path = os.path.join(valid_ann_dir, valid_ann_file)

    # Load the annotation
    with open(valid_ann_path, 'r') as f:
        valid_annotation = json.load(f)

    # Check the class type
    if valid_annotation.get("objects") and valid_annotation["objects"][0]["classTitle"] != "wheat":
        # Delete the image and annotation files
        os.remove(valid_img_path)
        os.remove(valid_ann_path)

# List image and annotation files
valid_img_files = sorted(os.listdir(valid_img_dir))
valid_ann_files = sorted(os.listdir(valid_ann_dir))

print("Number of validation images after cleaning:", len(valid_img_files))
print("Number of validation annotations after cleaning:", len(valid_ann_files))

for test_img_file, test_ann_file in zip(test_img_files, test_ann_files):
    test_img_path = os.path.join(test_img_dir, test_img_file)
    test_ann_path = os.path.join(test_ann_dir, test_ann_file)

    # Load the annotation
    with open(test_ann_path, 'r') as f:
        test_annotation = json.load(f)

    # Check the class type
    if test_annotation.get("objects") and test_annotation["objects"][0]["classTitle"] != "wheat":
        # Delete the image and annotation files
        os.remove(test_img_path)
        os.remove(test_ann_path)

# List image and annotation files
test_img_files = sorted(os.listdir(test_img_dir))
test_ann_files = sorted(os.listdir(test_ann_dir))

print("Number of testing images after cleaning:", len(test_img_files))
print("Number of testing annotations after cleaning:", len(test_ann_files))

"""Now, we have the object class, num of objects and the details of bounding boxes."""

# discover the "img" and "ann"
# Print the first five files in each directory
print("First five files in 'img':", img_files[:5])
print("First five files in 'ann':", ann_files[:5])

"""We can find that it's not sorted, so we need to pair them up artificially: ann name(.jpg) = file name.jpg(.json)"""

# dive into the format of annotation
sample_annotation = ann_files[0]
# Path to the annotation file
ann_path = os.path.join(ann_dir, sample_annotation)

# Load the JSON annotation
with open(ann_path, 'r') as f:
    annotation = json.load(f)

# Recursive function to remove empty fields
def clean_empty(data):
  # clean dicts
    if isinstance(data, dict):
        return {k: clean_empty(v) for k, v in data.items() if v not in [None, {}, [], ""]}
  # clean lists
    elif isinstance(data, list):
        return [clean_empty(v) for v in data if v not in [None, {}, [], ""]]
    else:
        return data

# Clean up empty fields from the annotation
cleaned_annotation = clean_empty(annotation)

# Print the cleaned JSON
print("Annotation in JSON format:")
print(json.dumps(cleaned_annotation, indent=4))

"""Try to get the images with bounding boxes.

The original format

Can skip this section
"""

from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# Match the first image and its corresponding annotation
image_number = 0
first_image_file = img_files[image_number]
first_annotation_file = first_image_file + ".json"  # Append .json to match annotation file

# Paths to the image and annotation files
first_img_path = os.path.join(img_dir, first_image_file)
first_ann_path = os.path.join(ann_dir, first_annotation_file)

# Open the image
first_img = Image.open(first_img_path).convert("RGB")

# Load the JSON annotation
with open(first_ann_path, 'r') as f:
    annotation = json.load(f)

# Extract bounding box information from the JSON
bounding_boxes = []
for obj in annotation["objects"]:
    if obj["geometryType"] == "rectangle" and "points" in obj:
        # Extract the exterior points as the bounding box
        x_min, y_min = obj["points"]["exterior"][0]
        x_max, y_max = obj["points"]["exterior"][1]
        bounding_boxes.append((x_min, y_min, x_max, y_max))

# Plot the original and annotated images side-by-side
fig, axes = plt.subplots(1, 2, figsize=(15, 10))
# the original image
axes[0].imshow(first_img)
axes[0].set_title(f"Original Image for Image{image_number + 1}")
axes[0].axis('off')
# the image with bounding boxes
axes[1].imshow(first_img)

# Add bounding boxes to the plot
for bbox in bounding_boxes:
    x_min, y_min, x_max, y_max = bbox
    width = x_max - x_min
    height = y_max - y_min
    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='red', facecolor='none')
    axes[1].add_patch(rect)

# Set title and remove axes for better display
axes[1].set_title(f"Bounding Boxes for Image{image_number + 1}")
axes[1].axis('off')

# Display the image
plt.show()

# Extract detected object
detected_objects = [obj["classTitle"] for obj in annotation.get("objects", [])]
print(f"Object Class is: {detected_objects[0]}")

# Count the number of detected objects
num_objects = len(detected_objects)
print(f"Num detected: {num_objects}")

# Print details for the bounding boxes
print("Bounding Boxes:")
for idx, bbox in enumerate(bounding_boxes, 1):
    print(f"Box {idx}: {bbox}")

"""transform it to YOLO format

"""



# Function to convert original annotations to YOLO format
def convert_to_yolo(json_data, class_mapping):
    image_width = json_data["size"]["width"]
    image_height = json_data["size"]["height"]
    yolo_annotations = []

    for obj in json_data['objects']:
        class_title = obj['classTitle']
        if class_title not in class_mapping:
            continue  # Skip unknown classes

        class_id = class_mapping[class_title]
        exterior = obj['points']['exterior']

        # Extract bounding box coordinates
        x_min, y_min = exterior[0]
        x_max, y_max = exterior[1]

        # Calculate YOLO format values
        x_center = ((x_min + x_max) / 2) / image_width
        y_center = ((y_min + y_max) / 2) / image_height
        width = (x_max - x_min) / image_width
        height = (y_max - y_min) / image_height

        # Format as YOLO annotation
        yolo_annotation = f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"
        yolo_annotations.append(yolo_annotation)

    return {
        "image_width": image_width,
        "image_height": image_height,
        "yolo_annotations": yolo_annotations
    }

# Class mapping (class name to class ID)
class_mapping = {
    "wheat": 0  # YOLO class ID for "wheat"
}

# Load and parse the annotation JSON (if it's a string or file)
if isinstance(annotation, str):  # Check if input is a JSON string
    annotation_json = json.loads(annotation)

# Proceed with YOLO conversion
yolo_data = convert_to_yolo(annotation, class_mapping)

# Save or print the YOLO annotations
for data in yolo_data:
    print(data)

print(yolo_data["image_height"])
print(yolo_data["image_width"])
print(yolo_data["yolo_annotations"])

# Parse YOLO annotations
bounding_boxes = []
for annotation in yolo_data["yolo_annotations"]:
    parts = annotation.split()
    x_center = float(parts[1]) * yolo_data["image_width"]
    y_center = float(parts[2]) * yolo_data["image_height"]
    width = float(parts[3]) * yolo_data["image_width"]
    height = float(parts[4]) * yolo_data["image_height"]

    # Calculate bounding box coordinates
    x_min = int(x_center - (width / 2))
    y_min = int(y_center - (height / 2))
    x_max = int(x_center + (width / 2))
    y_max = int(y_center + (height / 2))

    bounding_boxes.append((x_min, y_min, x_max, y_max))

# Plot the original and annotated images side-by-side
fig, axes = plt.subplots(1, 2, figsize=(15, 10))

# Original image
axes[0].imshow(first_img)
axes[0].set_title("Original Image")
axes[0].axis('off')

# Annotated image with bounding boxes
axes[1].imshow(first_img)
for bbox in bounding_boxes:
    x_min, y_min, x_max, y_max = bbox
    width = x_max - x_min
    height = y_max - y_min
    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='red', facecolor='none')
    axes[1].add_patch(rect)

axes[1].set_title("Image with Bounding Boxes")
axes[1].axis('off')

# Display the plot
plt.show()

# Count and display detected objects
num_objects = len(bounding_boxes)
print(f"Number of detected objects: {num_objects}")

# Print bounding box details
print("Bounding Boxes:")
for idx, bbox in enumerate(bounding_boxes, 1):
    print(f"Box {idx}: {bbox}")

"""It works, let's move to YOLOv4 model."""

# Commented out IPython magic to ensure Python compatibility.
# darknet
!git clone https://github.com/AlexeyAB/darknet
# %cd darknet

# Configure Darknet for YOLOv4
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile

!make



# change the format of annotation
def convert_to_yolo(json_dir, output_dir, image_dir, class_mapping):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    valid_images = []

    for json_file in os.listdir(json_dir):
        if json_file.endswith('.json'):
            with open(os.path.join(json_dir, json_file), 'r') as f:
                json_data = json.load(f)

            yolo_annotations = []
            image_width = json_data['size']['width']
            image_height = json_data['size']['height']

            # skip those not wheat
            for obj in json_data['objects']:
                class_title = obj['classTitle']
                if class_title not in class_mapping:
                    continue

                class_id = class_mapping[class_title]
                x_min, y_min = obj['points']['exterior'][0]
                x_max, y_max = obj['points']['exterior'][1]

                x_center = ((x_min + x_max) / 2) / image_width
                y_center = ((y_min + y_max) / 2) / image_height
                width = (x_max - x_min) / image_width
                height = (y_max - y_min) / image_height

                yolo_annotations.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

            # check if validated
            if yolo_annotations:
                annotation_name = os.path.splitext(json_file)[0] + '.txt'
                with open(os.path.join(output_dir, annotation_name), 'w') as out_file:
                    out_file.write("\n".join(yolo_annotations))

                image_name = os.path.splitext(json_file)[0] + '.jpg'
                if os.path.exists(os.path.join(image_dir, image_name)):
                    valid_images.append(os.path.join(image_dir, image_name))

    return valid_images

# dataset paths
train_image_dir = "/root/dataset-ninja/deepnir-fruit-detection/train/img"
train_annotation_dir = "/root/dataset-ninja/deepnir-fruit-detection/train/ann"
test_image_dir = "/root/dataset-ninja/deepnir-fruit-detection/test/img"
test_annotation_dir = "/root/dataset-ninja/deepnir-fruit-detection/test/ann"
valid_image_dir = "/root/dataset-ninja/deepnir-fruit-detection/valid/img"
valid_annotation_dir = "/root/dataset-ninja/deepnir-fruit-detection/valid/ann"

# output directories
train_output_dir = "data/train"
test_output_dir = "data/test"
valid_output_dir = "data/valid"

# selected class
class_mapping = {"wheat": 0}

train_list = convert_to_yolo(train_annotation_dir, train_output_dir, train_image_dir, class_mapping)
test_list = convert_to_yolo(test_annotation_dir, test_output_dir, test_image_dir, class_mapping)
valid_list = convert_to_yolo(valid_annotation_dir, valid_output_dir, valid_image_dir, class_mapping)

# configuration files
def create_yolo_files(train_list, test_list, valid_list, class_names, cfg_path, weights_path):
    os.makedirs('data', exist_ok=True)

    with open('data/train.txt', 'w') as train_file:
        train_file.writelines(f"{line}\n" for line in train_list)

    with open('data/test.txt', 'w') as test_file:
        test_file.writelines(f"{line}\n" for line in test_list)

    with open('data/valid.txt', 'w') as valid_file:
        valid_file.writelines(f"{line}\n" for line in valid_list)

    with open('data/obj.names', 'w') as names_file:
        names_file.writelines(f"{name}\n" for name in class_names)

    with open('data/obj.data', 'w') as data_file:
        data_file.write(f"classes = {len(class_names)}\n")
        data_file.write("train = data/train.txt\n")
        data_file.write("valid = data/valid.txt\n")
        data_file.write("names = data/obj.names\n")
        data_file.write("backup = backup/\n")

    os.makedirs('backup', exist_ok=True)
    if cfg_path:
        os.system(f'cp {cfg_path} cfg/')
    if weights_path:
        os.system(f'cp {weights_path} weights/')

class_names = ["wheat"]
cfg_path = "path/to/yolov4.cfg"
weights_path = "path/to/yolov4.weights"

# Update cfg file to match the number of classes
cfg_file = "cfg/yolov4.cfg"
with open(cfg_file, 'r') as file:
    cfg_lines = file.readlines()

with open(cfg_file, 'w') as file:
    for line in cfg_lines:
        if line.startswith("classes="):
            file.write(f"classes={len(class_names)}\n")
        elif line.startswith("filters="):
            filters = (len(class_names) + 5) * 3
            file.write(f"filters={filters}\n")
        else:
            file.write(line)

create_yolo_files(train_list, test_list, valid_list, class_names, cfg_path, weights_path)

!wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights

# Start training YOLOv4
!./darknet detector train data/obj.data cfg/yolov4.cfg yolov4.weights -map -dont_show -saveweights 100

test_images_dir = "/root/dataset-ninja/deepnir-fruit-detection/test/img"
test_annotations_dir = "/content/darknet/data/test"

# Check if annotations exist for all images
missing_annotations = []
for image_file in os.listdir(test_images_dir):
    if image_file.endswith((".jpg", ".png")):
        annotation_file = os.path.join(test_annotations_dir, os.path.splitext(image_file)[0] + ".txt")
        if not os.path.exists(annotation_file):
            missing_annotations.append(image_file)

print(f"Missing annotations: {missing_annotations}")

!./darknet detector map data/obj.data cfg/yolov4.cfg backup/yolov4_final.weights

def filter_annotations(input_dir, output_dir, valid_class_ids):
    """
    Filters annotations in YOLO format to include only valid class IDs.
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for file_name in os.listdir(input_dir):
        if file_name.endswith(".txt"):
            input_path = os.path.join(input_dir, file_name)
            output_path = os.path.join(output_dir, file_name)

            with open(input_path, "r") as infile, open(output_path, "w") as outfile:
                for line in infile:
                    class_id = int(line.split()[0])  # Extract class ID
                    if class_id in valid_class_ids:
                        outfile.write(line)

    print(f"Filtered annotations saved in {output_dir}")

# Paths to annotations
test_annotation_dir = "/content/darknet/data/test"
filtered_test_annotation_dir = "/content/darknet/data/test_filtered"

# Filter for the wheat class (class ID = 0)
filter_annotations(test_annotation_dir, filtered_test_annotation_dir, valid_class_ids=[0])

test_images_dir = "/root/dataset-ninja/deepnir-fruit-detection/test/img"
filtered_test_annotation_dir = "/content/darknet/data/test_filtered"

# Generate paths for test.txt
image_files = [f for f in os.listdir(test_images_dir) if f.endswith((".jpg", ".png"))]
filtered_test_images = [
    os.path.join(test_images_dir, img)
    for img in image_files
    if os.path.exists(os.path.join(filtered_test_annotation_dir, os.path.splitext(img)[0] + ".txt"))
]

with open("data/test.txt", "w") as f:
    f.write("\n".join(filtered_test_images))

print(f"Updated test.txt with {len(filtered_test_images)} filtered images.")

!./darknet detector map data/obj.data cfg/yolov4.cfg backup/yolov4_final.weights